{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 360)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "di = {'a': np.zeros(6), 'b': np.arange(360)[np.newaxis, :], 'c': 3}\n",
    "print(di['b'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.preprocessing import get_action_dim\n",
    "\n",
    "from env import PathFollowingEnv\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class ExpertDataset(Dataset):\n",
    "    def __init__(self, observations, actions):\n",
    "        self.observations = torch.FloatTensor(observations)\n",
    "        self.actions = torch.FloatTensor(actions)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.observations[idx], self.actions[idx]\n",
    "\n",
    "def generate_expert_data(env, n_episodes=1000, save_dir=\"expert_demonstrations\"):\n",
    "    \"\"\"Generate expert demonstrations and save to CSV files\"\"\"\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    csv_file = os.path.join(save_dir, f'expert_data_{timestamp}.csv')\n",
    "    \n",
    "    columns = [\n",
    "        'episode', 'step', 'success',\n",
    "        'current_x', 'current_y',\n",
    "        'goal_x', 'goal_y'\n",
    "    ]\n",
    "    for i in range(env.chunk_size):\n",
    "        columns.extend([f'waypoint_{i}_x', f'waypoint_{i}_y'])\n",
    "    columns.extend(['distance_to_goal', 'distance_to_next', 'timestep',\n",
    "                   'action_linear', 'action_angular'])\n",
    "    \n",
    "    # Write header to CSV\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_csv(csv_file, index=False, header=True)\n",
    "    \n",
    "    successful_episodes = 0\n",
    "    thresh = 0.1\n",
    "    \n",
    "    episode_pbar = tqdm(total=n_episodes, desc=\"Generating episodes\", position=0)\n",
    "    success_pbar = tqdm(total=n_episodes, desc=\"Successful episodes\", position=1)\n",
    "    \n",
    "    try:\n",
    "        for episode in range(n_episodes):\n",
    "            episode_data = []\n",
    "            \n",
    "            obs = env.reset()[0]\n",
    "            done = False\n",
    "            truncated = False\n",
    "            \n",
    "            path = env.path_manager.get_full_path()\n",
    "            \n",
    "            # Skip if path is empty or too short\n",
    "            if path is None or len(path) < 2:\n",
    "                episode_pbar.update(1)\n",
    "                continue\n",
    "                \n",
    "            current_pos = env.current_pos\n",
    "            current_theta = env.agent_theta\n",
    "            episode_success = False\n",
    "            \n",
    "            # Path following progress bar\n",
    "            path_pbar = tqdm(total=len(path)-1, desc=\"Following path\", \n",
    "                           position=2, leave=False)\n",
    "            \n",
    "            i = 0\n",
    "            while i < (len(path) - 1):\n",
    "                current_waypoint = path[i]\n",
    "                distance = np.linalg.norm(current_waypoint - current_pos)\n",
    "\n",
    "                if distance < thresh:\n",
    "                    i += 1\n",
    "                    path_pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Calculate expert action\n",
    "                dx = current_waypoint[0] - current_pos[0]\n",
    "                dy = current_waypoint[1] - current_pos[1]\n",
    "                desired_theta = (np.arctan2(dy, dx) + np.pi) % (2 * np.pi) - np.pi\n",
    "                \n",
    "                angle_diff = desired_theta - current_theta\n",
    "                angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi\n",
    "                \n",
    "                # Generate expert action\n",
    "                l = min(distance, 1.0) if abs(angle_diff) < np.pi/4 else 0.0\n",
    "                theta = np.clip(angle_diff / np.pi, -1.0, 1.0)\n",
    "                \n",
    "                action = np.array([l, theta])\n",
    "                \n",
    "                # Store step data\n",
    "                row = {\n",
    "                    'episode': successful_episodes,\n",
    "                    'step': env.current_step,\n",
    "                    'success': False,  # Will update later if successful\n",
    "                    'current_x': obs[0],\n",
    "                    'current_y': obs[1],\n",
    "                    'goal_x': obs[2],\n",
    "                    'goal_y': obs[3],\n",
    "                }\n",
    "                \n",
    "                # Add waypoints\n",
    "                for j in range(env.chunk_size):\n",
    "                    if 4 + j*2 + 1 < len(obs):  # Check if waypoint exists in observation\n",
    "                        row[f'waypoint_{j}_x'] = obs[4 + j*2]\n",
    "                        row[f'waypoint_{j}_y'] = obs[4 + j*2 + 1]\n",
    "                    else:\n",
    "                        row[f'waypoint_{j}_x'] = obs[-6]  # Use last valid waypoint\n",
    "                        row[f'waypoint_{j}_y'] = obs[-5]\n",
    "                \n",
    "                # Add metrics\n",
    "                row.update({\n",
    "                    'distance_to_goal': obs[-3],\n",
    "                    'distance_to_next': obs[-2],\n",
    "                    'timestep': obs[-1],\n",
    "                    'action_linear': action[0],\n",
    "                    'action_angular': action[1]\n",
    "                })\n",
    "                \n",
    "                episode_data.append(row)\n",
    "                \n",
    "                # Update environment\n",
    "                obs, reward, done, truncated, info = env.step(action)\n",
    "                \n",
    "                if done or truncated:\n",
    "                    episode_success = done\n",
    "                    break\n",
    "                    \n",
    "                current_pos = env.current_pos\n",
    "                current_theta = env.agent_theta\n",
    "                path_pbar.update(1)\n",
    "            \n",
    "            path_pbar.close()\n",
    "            \n",
    "            # If episode completed successfully, save it\n",
    "            if len(episode_data) > 0:\n",
    "                # Update success flag for all steps in episode\n",
    "                for step_data in episode_data:\n",
    "                    step_data['success'] = True\n",
    "                \n",
    "                # Append to CSV file\n",
    "                df = pd.DataFrame(episode_data)\n",
    "                df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "                \n",
    "                successful_episodes += 1\n",
    "                success_pbar.update(1)\n",
    "                \n",
    "                # Update progress bar postfix with stats\n",
    "                success_pbar.set_postfix({\n",
    "                    'len': len(episode_data),\n",
    "                    'dist': f\"{episode_data[-1]['distance_to_goal']:.3f}\"\n",
    "                })\n",
    "            \n",
    "            episode_pbar.update(1)\n",
    "            episode_pbar.set_postfix({'success_rate': f\"{successful_episodes/episode_pbar.n:.2%}\"})\n",
    "            \n",
    "    finally:\n",
    "        # Clean up progress bars\n",
    "        episode_pbar.close()\n",
    "        success_pbar.close()\n",
    "    \n",
    "    return csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demonstrations(csv_file, env):\n",
    "    \"\"\"Load demonstrations from single CSV file\"\"\"\n",
    "    world_max = np.array([8, 6])\n",
    "    world_limits = np.array([[-8, 8], [-6, 6]])\n",
    "    world_diag = np.linalg.norm(world_max)\n",
    "    max_episode_timesteps = 200\n",
    "\n",
    "    print(f\"Loading demonstrations from {csv_file}\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter successful episodes only\n",
    "    df = df[df['success'] == True]\n",
    "\n",
    "    df['current_x'] = df['current_x'] / world_max[0]\n",
    "    df['current_y'] = df['current_y'] / world_max[1]\n",
    "    df['goal_x'] = df['goal_x'] / world_max[0]\n",
    "    df['goal_y'] = df['goal_y'] / world_max[1]\n",
    "    for i in range(env.chunk_size):\n",
    "        df[f'waypoint_{i}_x'] = df[f'waypoint_{i}_x'] / world_max[0]\n",
    "        df[f'waypoint_{i}_y'] = df[f'waypoint_{i}_y'] / world_max[1]\n",
    "    df['distance_to_goal'] = df['distance_to_goal'] / world_diag\n",
    "    df['distance_to_next'] = df['distance_to_next'] / world_diag\n",
    "    df['timestep'] = df['timestep'] / max_episode_timesteps\n",
    "\n",
    "    # print(df.head())\n",
    "    # Extract observations\n",
    "    obs_cols = (\n",
    "        ['current_x', 'current_y', 'goal_x', 'goal_y'] +\n",
    "        [f'waypoint_{i}_x' for i in range(env.chunk_size)] +\n",
    "        [f'waypoint_{i}_y' for i in range(env.chunk_size)] +\n",
    "        ['distance_to_goal', 'distance_to_next', 'timestep']\n",
    "    )\n",
    "    \n",
    "    # Extract actions\n",
    "    action_cols = ['action_linear', 'action_angular']\n",
    "    \n",
    "    observations = df[obs_cols].values\n",
    "    actions = df[action_cols].values\n",
    "    \n",
    "    return observations, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     env = PathFollowingEnv(\n",
    "#         image_path=\"standalone_examples/api/omni.isaac.kit/TEST_FILES/New_WR_World.png\",\n",
    "#         algo=\"SAC\",\n",
    "#         max_episode_steps=1000,\n",
    "#         headless=True\n",
    "#     )\n",
    "    \n",
    "#     # Generate demonstrations\n",
    "#     csv_file = generate_expert_data(env, n_episodes=int(1e6), save_dir=\"/home/rahm/SIMPLE_LOGS/DATA\")\n",
    "    \n",
    "#     # Load and verify the data\n",
    "#     with tqdm(total=1, desc=\"Loading and verifying data\") as pbar:\n",
    "#         observations, actions = load_demonstrations(csv_file)\n",
    "#         pbar.update(1)\n",
    "#         pbar.set_postfix({\n",
    "#             'obs_shape': observations.shape,\n",
    "#             'act_shape': actions.shape\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = PathFollowingEnv(\n",
    "#         image_path=\"/home/rahm/.local/share/ov/pkg/isaac-sim-4.2.0/standalone_examples/api/omni.isaac.kit/TEST_FILES/New_WR_World.png\",\n",
    "#         algo=\"SAC\",\n",
    "#         max_episode_steps=1000,\n",
    "#         headless=False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_policy(\n",
    "    env,\n",
    "    policy,\n",
    "    expert_data,\n",
    "    device=\"cuda\",\n",
    "    batch_size=512,\n",
    "    epochs=100,\n",
    "    learning_rate=3e-4,\n",
    "    val_split=0.1,\n",
    "    early_stopping_patience=25,\n",
    "):\n",
    "    \"\"\"Pretrain policy using behavioral cloning with optimized GPU implementation\"\"\"\n",
    "    observations, actions = expert_data\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    split_idx = int(len(observations) * (1 - val_split))\n",
    "    train_dataset = ExpertDataset(observations[:split_idx], actions[:split_idx])\n",
    "    val_dataset = ExpertDataset(observations[split_idx:], actions[split_idx:])\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=8,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=8,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    optimizer = optim.AdamW(policy.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    policy = policy.to(device)\n",
    "    policy = torch.compile(policy)  # Using torch.compile for speedup\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        policy.train()\n",
    "        train_loss = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        \n",
    "        for batch_obs, batch_actions in train_pbar:\n",
    "            batch_obs = batch_obs.to(device, non_blocking=True)\n",
    "            batch_actions = batch_actions.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Mixed precision training\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                pred_actions = policy(batch_obs)\n",
    "                loss = criterion(pred_actions[0], batch_actions)\n",
    "            \n",
    "            theta_error = criterion(pred_actions[0][:, 1], batch_actions[:, 1])\n",
    "            # loss += theta_error\n",
    "            wandb.log({\"bc_train/theta_error\": np.rad2deg(theta_error.item()*np.pi)})\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
    "            \n",
    "            wandb.log({\n",
    "                \"bc_train/loss\": loss.item(),\n",
    "                \"bc_train/learning_rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        policy.eval()\n",
    "        val_loss = 0\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_obs, batch_actions in val_pbar:\n",
    "                batch_obs = batch_obs.to(device, non_blocking=True)\n",
    "                batch_actions = batch_actions.to(device, non_blocking=True)\n",
    "                \n",
    "                pred_actions = policy(batch_obs)\n",
    "                loss = criterion(pred_actions[0], batch_actions)\n",
    "                val_loss += loss.item()\n",
    "                val_pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"bc_val/loss\": avg_val_loss,\n",
    "            \"bc_train/avg_loss\": avg_train_loss,\n",
    "            \"bc_train/epoch\": epoch\n",
    "        })\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': policy.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, \"best_bc_policy.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "                break\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC, PPO, TD3\n",
    "\n",
    "def main():\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"pretraining_BC\", name=\"bc_pretraining_PPO\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True  # Enable cudnn autotuner\n",
    "    \n",
    "    # Create environment\n",
    "    env = PathFollowingEnv(\n",
    "        image_path=\"/home/rahm/.local/share/ov/pkg/isaac-sim-4.2.0/standalone_examples/api/omni.isaac.kit/TEST_FILES/New_WR_World.png\",\n",
    "        algo=\"PPO\",\n",
    "        max_episode_steps=1000,\n",
    "        headless=True,\n",
    "        enable_wandb=False\n",
    "    )\n",
    "    \n",
    "    # Generate expert demonstrations using RRT*\n",
    "    csv_file = \"/home/rahm/SIMPLE_LOGS/expert_data.csv\"\n",
    "    observations, actions = load_demonstrations(csv_file, env)\n",
    "    expert_data = (observations, actions)\n",
    "\n",
    "    # print(F\"expert_data: {expert_data}\")\n",
    "    \n",
    "    # Initialize new policy for pretraining\n",
    "    policy = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=3e-4,\n",
    "        verbose=1,\n",
    "        n_steps=2048,\n",
    "        n_epochs=10,\n",
    "        batch_size=64,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.01,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        normalize_advantage=True,\n",
    "        device=device,\n",
    "        policy_kwargs={\n",
    "            \"net_arch\": dict(\n",
    "                pi=[256, 512, 512, 256],\n",
    "                qf=[256, 512, 512, 256]\n",
    "            ),\n",
    "            \"optimizer_class\": optim.AdamW,\n",
    "            \"optimizer_kwargs\": dict(weight_decay=1e-5)\n",
    "        }\n",
    "    ).policy\n",
    "    \n",
    "    # Pretrain the policy\n",
    "    pretrained_policy = pretrain_policy(\n",
    "        env=env,\n",
    "        policy=policy,\n",
    "        expert_data=expert_data,\n",
    "        batch_size=1024,\n",
    "        epochs=100,\n",
    "        learning_rate=3e-4,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Save the final pretrained policy\n",
    "    torch.save({\n",
    "        'model_state_dict': pretrained_policy.state_dict(),\n",
    "        # 'final_loss': best_val_loss,\n",
    "    }, \"Nnew2_final_bc_policy.pth\")\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC, PPO, TD3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from env import PathFollowingEnv\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"pretraining_Eval\", name=\"bc_pretraining_PPO\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True  # Enable cudnn autotuner\n",
    "\n",
    "# Create environment\n",
    "env = PathFollowingEnv(\n",
    "    image_path=\"/home/rahm/.local/share/ov/pkg/isaac-sim-4.2.0/standalone_examples/api/omni.isaac.kit/TEST_FILES/New_WR_World.png\",\n",
    "    algo=\"PPO\",\n",
    "    max_episode_steps=1000,\n",
    "    headless=False,\n",
    "    enable_wandb=False,\n",
    "    enable_reward_monitor=True,\n",
    ")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs={\n",
    "        \"net_arch\": dict(\n",
    "            pi=[256, 512, 512, 256],\n",
    "            qf=[256, 512, 512, 256]\n",
    "        ),\n",
    "        \"optimizer_class\": optim.AdamW,\n",
    "        \"optimizer_kwargs\": dict(weight_decay=1e-5)\n",
    "    }\n",
    ")\n",
    "\n",
    "saved_model = torch.load(\"New_final_bc_policy.pth\")\n",
    "saved_model['model_state_dict'] = {k.replace('_orig_mod.', ''): v for k, v in saved_model['model_state_dict'].items()}\n",
    "\n",
    "model.policy.load_state_dict(saved_model['model_state_dict'])\n",
    "evaluate_policy(model, env, n_eval_episodes=100, deterministic=True)\n",
    "\n",
    "# Save the final pretrained policy\n",
    "# torch.save({\n",
    "#     'model_state_dict': pretrained_policy.state_dict(),\n",
    "#     # 'final_loss': best_val_loss,\n",
    "# }, \"final_bc_policy.pth\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading demonstrations from /home/rahm/SIMPLE_LOGS/expert_data.csv\n",
      "(11470274, 31)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.preprocessing import get_action_dim\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "from env import PathFollowingEnv\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class ExpertDataset(Dataset):\n",
    "    def __init__(self, observations, actions):\n",
    "        self.observations = torch.FloatTensor(observations)\n",
    "        self.actions = torch.FloatTensor(actions)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.observations[idx], self.actions[idx]\n",
    "\n",
    "def load_demonstrations(csv_file, env):\n",
    "    \"\"\"Load demonstrations from single CSV file\"\"\"\n",
    "    world_max = np.array([8, 6])\n",
    "    world_limits = np.array([[-8, 8], [-6, 6]])\n",
    "    world_diag = np.linalg.norm(world_max)\n",
    "    max_episode_timesteps = 200\n",
    "\n",
    "    print(f\"Loading demonstrations from {csv_file}\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter successful episodes only\n",
    "    df = df[df['success'] == True]\n",
    "\n",
    "    df['current_x'] = df['current_x'] / world_max[0]\n",
    "    df['current_y'] = df['current_y'] / world_max[1]\n",
    "    df['goal_x'] = df['goal_x'] / world_max[0]\n",
    "    df['goal_y'] = df['goal_y'] / world_max[1]\n",
    "    for i in range(env.chunk_size):\n",
    "        df[f'waypoint_{i}_x'] = df[f'waypoint_{i}_x'] / world_max[0]\n",
    "        df[f'waypoint_{i}_y'] = df[f'waypoint_{i}_y'] / world_max[1]\n",
    "    df['distance_to_goal'] = df['distance_to_goal'] / world_diag\n",
    "    df['distance_to_next'] = df['distance_to_next'] / world_diag\n",
    "    df['timestep'] = df['timestep'] / max_episode_timesteps\n",
    "\n",
    "    # print(df.head())\n",
    "    # Extract observations\n",
    "    obs_cols = (\n",
    "        ['current_x', 'current_y', 'goal_x', 'goal_y'] +\n",
    "        [f'waypoint_{i}_x' for i in range(env.chunk_size)] +\n",
    "        [f'waypoint_{i}_y' for i in range(env.chunk_size)] +\n",
    "        ['distance_to_goal', 'distance_to_next', 'timestep']\n",
    "    )\n",
    "    \n",
    "    # Extract actions\n",
    "    action_cols = ['action_linear', 'action_angular']\n",
    "    \n",
    "    observations = df[obs_cols].values\n",
    "    actions = df[action_cols].values\n",
    "    \n",
    "    return observations, actions\n",
    "\n",
    "def pretrain_policy(\n",
    "    env,\n",
    "    policy,\n",
    "    expert_data,\n",
    "    device=\"cuda\",\n",
    "    batch_size=256,\n",
    "    epochs=20,\n",
    "    learning_rate=3e-4,\n",
    "    val_split=0.1,\n",
    "    early_stopping_patience=10,\n",
    "):\n",
    "    \"\"\"Pretrain policy using behavioral cloning with optimized GPU implementation\"\"\"\n",
    "    observations, actions = expert_data\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    split_idx = int(len(observations) * (1 - val_split))\n",
    "    train_dataset = ExpertDataset(observations[:split_idx], actions[:split_idx])\n",
    "    val_dataset = ExpertDataset(observations[split_idx:], actions[split_idx:])\n",
    "\n",
    "    alpha = 0.4\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=8,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=8,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    optimizer = optim.AdamW(policy.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    policy = policy.to(device)\n",
    "    policy = torch.compile(policy)  # Using torch.compile for speedup\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        policy.train()\n",
    "        train_loss = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        \n",
    "        for batch_obs, batch_actions in train_pbar:\n",
    "            batch_obs = batch_obs.to(device, non_blocking=True)\n",
    "            batch_actions = batch_actions.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Mixed precision training\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                pred_actions = policy(batch_obs)\n",
    "                loss_l = criterion(pred_actions[:, 0], batch_actions[:, 0])\n",
    "                loss_theta = criterion(pred_actions[:, 1], batch_actions[:, 1])\n",
    "                loss = alpha*loss_l + (1-alpha)*loss_theta\n",
    "\n",
    "            theta_error = criterion(pred_actions[:, 1], batch_actions[:, 1])\n",
    "            # loss += theta_error\n",
    "            wandb.log({\"bc_train/theta_error\": np.rad2deg(theta_error.item()*np.pi)})\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
    "            \n",
    "            wandb.log({\n",
    "                \"bc_train/loss\": loss.item(),\n",
    "                \"bc_train/learning_rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        policy.eval()\n",
    "        val_loss = 0\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_obs, batch_actions in val_pbar:\n",
    "                batch_obs = batch_obs.to(device, non_blocking=True)\n",
    "                batch_actions = batch_actions.to(device, non_blocking=True)\n",
    "                \n",
    "                pred_actions = policy(batch_obs)\n",
    "                loss_l = criterion(pred_actions[:, 0], batch_actions[:, 0])\n",
    "                loss_theta = criterion(pred_actions[:, 1], batch_actions[:, 1])\n",
    "                loss = alpha*loss_l + (1-alpha)*loss_theta\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"bc_val/loss\": avg_val_loss,\n",
    "            \"bc_train/avg_loss\": avg_train_loss,\n",
    "            \"bc_train/epoch\": epoch\n",
    "        })\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': policy.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, \"best_bc_policy.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "                break\n",
    "\n",
    "    return policy\n",
    "\n",
    "from stable_baselines3 import SAC, PPO, TD3\n",
    "\n",
    "def main():\n",
    "    # algo = args.algo.upper()\n",
    "    # Initialize wandb\n",
    "    # wandb.init(project=\"pretraining_BC\", name=f\"bc_pretraining_{algo}\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True  # Enable cudnn autotuner\n",
    "    \n",
    "    # Create environment\n",
    "    env = PathFollowingEnv(\n",
    "        image_path=\"/home/rahm/.local/share/ov/pkg/isaac-sim-4.2.0/standalone_examples/api/omni.isaac.kit/TEST_FILES/New_WR_World.png\",\n",
    "        algo_run=\"sac\",\n",
    "        max_episode_steps=1000,\n",
    "        headless=True,\n",
    "        enable_wandb=False\n",
    "    )\n",
    "    \n",
    "    # Generate expert demonstrations using RRT*\n",
    "    csv_file = \"/home/rahm/SIMPLE_LOGS/expert_data.csv\"\n",
    "    observations, actions = load_demonstrations(csv_file, env)\n",
    "    expert_data = (observations, actions)\n",
    "\n",
    "    print(observations.shape)\n",
    "\n",
    "    # # print(F\"expert_data: {expert_data}\")\n",
    "    # policy_kwargs = {\n",
    "    #             \"net_arch\": dict(\n",
    "    #                 pi=[32, 64, 64, 64, 64, 64, 64, 64, 64],\n",
    "    #                 qf=[32, 64, 64, 64, 64, 64, 64, 64, 64]\n",
    "    #             ),\n",
    "    #             \"optimizer_class\": optim.AdamW,\n",
    "    #             \"optimizer_kwargs\": dict(weight_decay=1e-5)\n",
    "    #         }\n",
    "    \n",
    "    # # Initialize new policy for pretraining\n",
    "    # if algo.upper() == \"PPO\":\n",
    "    #     policy = PPO(\n",
    "    #         \"MlpPolicy\",\n",
    "    #         env,\n",
    "    #         learning_rate=3e-4,\n",
    "    #         verbose=1,\n",
    "    #         n_steps=2048,\n",
    "    #         n_epochs=10,\n",
    "    #         batch_size=64,\n",
    "    #         gamma=0.99,\n",
    "    #         gae_lambda=0.95,\n",
    "    #         clip_range=0.2,\n",
    "    #         ent_coef=0.01,\n",
    "    #         vf_coef=0.5,\n",
    "    #         max_grad_norm=0.5,\n",
    "    #         normalize_advantage=True,\n",
    "    #         device=device,\n",
    "    #         policy_kwargs=policy_kwargs,\n",
    "    #     ).policy\n",
    "    # elif algo.upper() == \"SAC\":\n",
    "    #     policy = SAC(\n",
    "    #             \"MlpPolicy\",\n",
    "    #             env,\n",
    "    #             learning_rate=3e-4,\n",
    "    #             buffer_size=1000000,\n",
    "    #             batch_size=256,\n",
    "    #             ent_coef='auto',\n",
    "    #             gamma=0.99,\n",
    "    #             tau=0.005,\n",
    "    #             train_freq=1,\n",
    "    #             gradient_steps=1,\n",
    "    #             learning_starts=10000,\n",
    "    #             policy_kwargs=policy_kwargs,\n",
    "    #             device=device,\n",
    "    #             verbose=1,\n",
    "    #         ).policy\n",
    "    # elif algo.upper() == \"TD3\":\n",
    "    #     n_actions = env.action_space.shape[-1]\n",
    "    #     action_noise = NormalActionNoise(\n",
    "    #         mean=np.zeros(n_actions),\n",
    "    #         sigma=0.1 * np.ones(n_actions)\n",
    "    #     )\n",
    "\n",
    "    #     policy = TD3(\n",
    "    #             \"MlpPolicy\",\n",
    "    #             env,\n",
    "    #             learning_rate=0.001,\n",
    "    #             buffer_size=1000000,\n",
    "    #             learning_starts=100,\n",
    "    #             batch_size=256,\n",
    "    #             tau=0.005,\n",
    "    #             gamma=0.99,\n",
    "    #             train_freq=1,\n",
    "    #             gradient_steps=1,\n",
    "    #             action_noise=action_noise,\n",
    "    #             policy_delay=2,\n",
    "    #             target_policy_noise=0.2,\n",
    "    #             target_noise_clip=0.5,\n",
    "    #             device=device,\n",
    "    #             verbose=1\n",
    "    #         ).policy\n",
    "\n",
    "    # # Pretrain the policy\n",
    "    # pretrained_policy = pretrain_policy(\n",
    "    #     env=env,\n",
    "    #     policy=policy,\n",
    "    #     expert_data=expert_data,\n",
    "    #     batch_size=1024,\n",
    "    #     epochs=100,\n",
    "    #     learning_rate=3e-4,\n",
    "    #     device=device\n",
    "    # )\n",
    "    \n",
    "    # # Save the final pretrained policy\n",
    "    # torch.save({\n",
    "    #     'model_state_dict': pretrained_policy.state_dict(),\n",
    "    #     # 'final_loss': best_val_loss,\n",
    "    # }, \"TD3_Pretrained.pth\")\n",
    "    \n",
    "    # wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--algo\", type=str, default=\"td3\", choices=[\"ppo\", \"sac\", \"td3\"])\n",
    "    # parser.add_argument(\"--csv\", type=str, default=\"expert_data.csv\")\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.eye(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _ray_march(start_x, start_y, angle, resolution, max_distance, img_width, img_height, binary_img):\n",
    "    \"\"\"Optimized ray marching for a single ray using Numba\"\"\"\n",
    "    dx = np.cos(angle)\n",
    "    dy = -np.sin(angle)  # Negative because image coordinates are flipped vertically\n",
    "    \n",
    "    x, y = start_x, start_y\n",
    "    distance = 0.0\n",
    "    \n",
    "    while 0 <= int(x) < img_width and 0 <= int(y) < img_height and distance < max_distance:\n",
    "        if binary_img[int(y), int(x)] == 0:  # Hit an obstacle (black pixel)\n",
    "            return distance\n",
    "        x += dx * resolution\n",
    "        y += dy * resolution\n",
    "        distance += resolution\n",
    "    \n",
    "    return max_distance\n",
    "\n",
    "def lidar_simulation_from_image(image_path, left_corner, right_corner, current_pos, goal_pos, resolution=1.0, fov=360, num_rays=360, max_distance=12.0):\n",
    "    \"\"\"\n",
    "    Simulates SLAMTEC RPLiDAR A2 specifications:\n",
    "    - Angular Resolution: 0.9° or 1°\n",
    "    - Scanning Frequency: 10Hz\n",
    "    - Range: 12m\n",
    "    - Sample Duration: ~0.25ms per sample\n",
    "    \"\"\"\n",
    "\n",
    "    img = np.array(Image.open(image_path).convert('L'))  # Convert to grayscale\n",
    "    binary_img = (img > 128).astype(np.uint8)  # Threshold to create a binary map\n",
    "    binary_img = cv2.resize(binary_img, (0,0), fx=0.25, fy=0.25)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    img_height, img_width = binary_img.shape\n",
    "    \n",
    "    # Calculate resolution scaling factors\n",
    "    resolution_x = img_width / (right_corner[0] - left_corner[0])\n",
    "    resolution_y = img_height / (right_corner[1] - left_corner[1])\n",
    "    \n",
    "    # Convert world coordinates to image coordinates\n",
    "    img_x = int((current_pos[0] - left_corner[0]) * resolution_x)\n",
    "    img_y = int((current_pos[1] - left_corner[1]) * resolution_y)\n",
    "    \n",
    "    # Initialize arrays for storing points\n",
    "    angles = np.linspace(0, np.deg2rad(fov), num_rays, endpoint=False)\n",
    "    distances = np.zeros(num_rays)\n",
    "    \n",
    "    # Ray march for each angle\n",
    "    for i, angle in enumerate(angles):\n",
    "        distances[i] = _ray_march(\n",
    "            img_x, img_y, angle, \n",
    "            resolution, max_distance,\n",
    "            img_width, img_height, \n",
    "            binary_img\n",
    "        )\n",
    "    \n",
    "    # Convert distances and angles to cartesian coordinates (relative to robot)\n",
    "    x_coords = distances * np.cos(angles)\n",
    "    y_coords = distances * np.sin(angles)\n",
    "    points = np.column_stack((x_coords, y_coords))\n",
    "    \n",
    "    # Scale points back to world coordinates\n",
    "    points[:, 0] /= resolution_x\n",
    "    points[:, 1] /= resolution_y\n",
    "    \n",
    "    return points\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"/home/rahm/.local/share/ov/pkg/isaac-sim-4.2.0/standalone_examples/api/omni.isaac.kit/TEST_FILES/New_WR_World.png\"  # Replace with the path to your image\n",
    "    resolution = 1  # Distance step in pixels\n",
    "    left = (-10, 7)\n",
    "    right = (10, -7)\n",
    "    start = (0, -3.5)\n",
    "    end = (5, -1)\n",
    "    fov = 360\n",
    "    num_rays = 720\n",
    "    max_distance = 250\n",
    "    lidar_simulation_from_image(image_path, left, right, start, end, resolution, fov, num_rays, max_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _ray_march(start_x, start_y, angle, resolution, max_distance, img_width, img_height, binary_img):\n",
    "    \"\"\"Optimized ray marching for a single ray using Numba\"\"\"\n",
    "    dx = np.cos(angle)\n",
    "    dy = -np.sin(angle)  # Negative because image coordinates are flipped vertically\n",
    "    \n",
    "    x, y = start_x, start_y\n",
    "    distance = 0.0\n",
    "    \n",
    "    while 0 <= int(x) < img_width and 0 <= int(y) < img_height and distance < max_distance:\n",
    "        if binary_img[int(y), int(x)] == 0:  # Hit an obstacle (black pixel)\n",
    "            return distance\n",
    "        x += dx * resolution\n",
    "        y += dy * resolution\n",
    "        distance += resolution\n",
    "    \n",
    "    return max_distance\n",
    "\n",
    "def lidar_simulation_from_image(binary_img, left_corner, right_corner, current_pos, goal_pos, resolution=1.0, fov=360, num_rays=360, max_distance=10.0):\n",
    "    \"\"\"\n",
    "    Simulates SLAMTEC RPLiDAR A2 specifications:\n",
    "    - Angular Resolution: 0.9° or 1°\n",
    "    - Scanning Frequency: 10Hz\n",
    "    - Range: 12m\n",
    "    - Sample Duration: ~0.25ms per sample\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    img_height, img_width = binary_img.shape\n",
    "    \n",
    "    # Calculate resolution scaling factors\n",
    "    resolution_x = img_width / (right_corner[0] - left_corner[0])\n",
    "    resolution_y = img_height / (right_corner[1] - left_corner[1])\n",
    "    \n",
    "    # Convert world coordinates to image coordinates\n",
    "    img_x = int((current_pos[0] - left_corner[0]) * resolution_x)\n",
    "    img_y = int((current_pos[1] - left_corner[1]) * resolution_y)\n",
    "    \n",
    "    # Initialize arrays for storing points\n",
    "    angles = np.linspace(0, np.deg2rad(fov), num_rays, endpoint=False)\n",
    "    distances = np.zeros(num_rays)\n",
    "    \n",
    "    # Ray march for each angle\n",
    "    for i, angle in enumerate(angles):\n",
    "        distances[i] = _ray_march(\n",
    "            img_x, img_y, angle, \n",
    "            resolution, max_distance,\n",
    "            img_width, img_height, \n",
    "            binary_img\n",
    "        )\n",
    "    \n",
    "    # Convert distances and angles to cartesian coordinates (relative to robot)\n",
    "    x_coords = distances * np.cos(angles)\n",
    "    y_coords = distances * np.sin(angles)\n",
    "    points = np.column_stack((x_coords, y_coords))\n",
    "    \n",
    "    # Scale points back to world coordinates\n",
    "    points[:, 0] /= resolution_x\n",
    "    points[:, 1] /= resolution_y\n",
    "    \n",
    "    return points\n",
    "\n",
    "def visualize_lidar(img_width, img_height, current_pos, lidar_points, world_to_img_func, color=(255, 0, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Visualize LiDAR points on an image using cv2\n",
    "    \n",
    "    Args:\n",
    "        img_width: Width of the visualization image\n",
    "        img_height: Height of the visualization image\n",
    "        current_pos: Current position of the robot in world coordinates\n",
    "        lidar_points: Array of LiDAR points relative to robot position\n",
    "        world_to_img_func: Function to convert world coordinates to image coordinates\n",
    "        color: Color of LiDAR points (B,G,R)\n",
    "        thickness: Thickness of LiDAR points\n",
    "    \"\"\"\n",
    "    # Create visualization layer\n",
    "    lidar_layer = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    if lidar_points is not None:\n",
    "        # Convert robot position to image coordinates\n",
    "        robot_img_pos = world_to_img_func(current_pos[0], current_pos[1])\n",
    "        \n",
    "        # Draw LiDAR rays\n",
    "        for point in lidar_points:\n",
    "            # Convert LiDAR point to world coordinates\n",
    "            world_x = current_pos[0] + point[0]\n",
    "            world_y = current_pos[1] + point[1]\n",
    "            \n",
    "            # Convert to image coordinates\n",
    "            point_img_pos = world_to_img_func(world_x, world_y)\n",
    "            \n",
    "            # Draw line from robot to LiDAR point\n",
    "            cv2.line(lidar_layer, robot_img_pos, point_img_pos, color, thickness)\n",
    "            \n",
    "            # Draw point at LiDAR hit\n",
    "            cv2.circle(lidar_layer, point_img_pos, thickness+1, color, -1)\n",
    "    \n",
    "    return lidar_layer\n",
    "\n",
    "def plot_lidar_polar(img_width, img_height, lidar_points, max_distance=12.0):\n",
    "    \"\"\"\n",
    "    Create a polar plot of LiDAR data\n",
    "    \n",
    "    Args:\n",
    "        img_width: Width of the plot\n",
    "        img_height: Height of the plot\n",
    "        lidar_points: Array of LiDAR points relative to robot position\n",
    "        max_distance: Maximum LiDAR range\n",
    "    \"\"\"\n",
    "    # Create polar plot image (black background)\n",
    "    polar_img = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Draw circular grid\n",
    "    center = (img_width // 2, img_height // 2)\n",
    "    max_radius = min(img_width, img_height) // 2 - 20\n",
    "    \n",
    "    # Draw concentric circles\n",
    "    num_circles = 4\n",
    "    for i in range(1, num_circles + 1):\n",
    "        radius = int(max_radius * i / num_circles)\n",
    "        cv2.circle(polar_img, center, radius, (50, 50, 50), 1)\n",
    "        # Add range label\n",
    "        range_text = f\"{max_distance * i / num_circles:.1f}m\"\n",
    "        cv2.putText(polar_img, range_text, \n",
    "                   (center[0] + radius + 5, center[1]), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)\n",
    "    \n",
    "    # Draw angle lines\n",
    "    for angle in range(0, 360, 45):\n",
    "        radian = np.deg2rad(angle)\n",
    "        end_x = int(center[0] + max_radius * np.cos(radian))\n",
    "        end_y = int(center[1] - max_radius * np.sin(radian))\n",
    "        cv2.line(polar_img, center, (end_x, end_y), (50, 50, 50), 1)\n",
    "        # Add angle label\n",
    "        label_x = int(center[0] + (max_radius + 20) * np.cos(radian))\n",
    "        label_y = int(center[1] - (max_radius + 20) * np.sin(radian))\n",
    "        cv2.putText(polar_img, f\"{angle}°\", \n",
    "                   (label_x, label_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)\n",
    "    \n",
    "    if lidar_points is not None:\n",
    "        # Plot LiDAR points\n",
    "        for point in lidar_points:\n",
    "            # Convert cartesian to polar coordinates\n",
    "            distance = np.sqrt(point[0]**2 + point[1]**2)\n",
    "            angle = np.arctan2(-point[1], point[0])  # Negative y for correct orientation\n",
    "            \n",
    "            # Scale distance to image size\n",
    "            scaled_distance = (distance / max_distance) * max_radius\n",
    "            \n",
    "            # Convert to image coordinates\n",
    "            x = int(center[0] + scaled_distance * np.cos(angle))\n",
    "            y = int(center[1] - scaled_distance * np.sin(angle))\n",
    "            \n",
    "            # Draw point\n",
    "            cv2.circle(polar_img, (x, y), 2, (0, 0, 255), -1)\n",
    "    \n",
    "    return polar_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Test function for LiDAR simulation and visualization\"\"\"\n",
    "    # Parameters\n",
    "    image_path = \"New_WR_World.png\"  # Replace with your image path\n",
    "    img_width, img_height = 800, 600\n",
    "    world_limits = ((-10, 8), (10, -8))  # (left_corner, right_corner)\n",
    "    \n",
    "    # Load and process the world image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image from {image_path}\")\n",
    "    \n",
    "    # Resize and threshold image\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    binary_img = (img > 128).astype(np.uint8)\n",
    "    \n",
    "    # Create window for visualization\n",
    "    cv2.namedWindow('LiDAR Test', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('LiDAR Test', img_width * 2, img_height)\n",
    "    \n",
    "    # Initial position and parameters\n",
    "    current_pos = np.array([0.0, 0.0])\n",
    "    goal_pos = np.array([5.0, 5.0])\n",
    "    lidar_specs = [1, 360, 720, 12]  # [resolution, FOV, #Rays, max_distance]\n",
    "    \n",
    "    def world_to_img_left(x, y):\n",
    "        \"\"\"Convert world coordinates to left panel image coordinates\"\"\"\n",
    "        img_x = int((x - world_limits[0][0]) * (img_width / (world_limits[1][0] - world_limits[0][0])))\n",
    "        img_y = int((world_limits[0][1] - y) * (img_height / (world_limits[0][1] - world_limits[1][1])))\n",
    "        return img_x, img_y\n",
    "\n",
    "    def world_to_img_right(x, y):\n",
    "        \"\"\"Convert world coordinates to right panel image coordinates\"\"\"\n",
    "        img_x = int((x - world_limits[0][0]) * (img_width / (world_limits[1][0] - world_limits[0][0]))) + img_width\n",
    "        img_y = int((world_limits[0][1] - y) * (img_height / (world_limits[0][1] - world_limits[1][1])))\n",
    "        return img_x, img_y\n",
    "\n",
    "    # Main loop\n",
    "    angle = 0.0\n",
    "    running = True\n",
    "    while running:\n",
    "        # Create combined image\n",
    "        combined_img = np.zeros((img_height, img_width * 2, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Copy world image to both panels\n",
    "        world_img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        combined_img[:, :img_width] = world_img_color\n",
    "        combined_img[:, img_width:] = world_img_color\n",
    "        \n",
    "        # Update position (circular motion for testing)\n",
    "        angle += 0.02\n",
    "        current_pos = np.array([\n",
    "            3.0 * np.cos(angle),\n",
    "            3.0 * np.sin(angle)\n",
    "        ])\n",
    "        \n",
    "        # Simulate LiDAR\n",
    "        lidar_points = lidar_simulation_from_image(\n",
    "            binary_img,\n",
    "            world_limits[0],\n",
    "            world_limits[1],\n",
    "            current_pos,\n",
    "            goal_pos,\n",
    "            lidar_specs[0],\n",
    "            lidar_specs[1],\n",
    "            lidar_specs[2],\n",
    "            lidar_specs[3]\n",
    "        )\n",
    "        \n",
    "        # Draw LiDAR visualization on both panels\n",
    "        lidar_layer_left = visualize_lidar(\n",
    "            img_width, img_height,\n",
    "            current_pos,\n",
    "            lidar_points,\n",
    "            world_to_img_left,\n",
    "            color=(255, 0, 0),\n",
    "            thickness=1\n",
    "        )\n",
    "        lidar_layer_right = visualize_lidar(\n",
    "            img_width, img_height,\n",
    "            current_pos,\n",
    "            lidar_points,\n",
    "            world_to_img_right,\n",
    "            color=(255, 0, 0),\n",
    "            thickness=1\n",
    "        )\n",
    "        \n",
    "        # Blend LiDAR visualization\n",
    "        combined_img[:, :img_width] = cv2.addWeighted(\n",
    "            combined_img[:, :img_width], 1.0,\n",
    "            lidar_layer_left, 0.7,\n",
    "            0\n",
    "        )\n",
    "        combined_img[:, img_width:] = cv2.addWeighted(\n",
    "            combined_img[:, img_width:], 1.0,\n",
    "            lidar_layer_right, 0.7,\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Add polar plot\n",
    "        polar_size = 200\n",
    "        polar_plot = plot_lidar_polar(\n",
    "            polar_size, polar_size,\n",
    "            lidar_points,\n",
    "            max_distance=lidar_specs[3]\n",
    "        )\n",
    "        \n",
    "        # Place polar plot in top-right corner\n",
    "        margin = 10\n",
    "        combined_img[margin:margin+polar_size, \n",
    "                    img_width*2-polar_size-margin:img_width*2-margin] = polar_plot\n",
    "        \n",
    "        # Draw robot position\n",
    "        robot_pos_left = world_to_img_left(current_pos[0], current_pos[1])\n",
    "        robot_pos_right = world_to_img_right(current_pos[0], current_pos[1])\n",
    "        cv2.circle(combined_img, robot_pos_left, 5, (0, 255, 255), -1)  # Yellow dot\n",
    "        cv2.circle(combined_img, robot_pos_right, 5, (0, 255, 255), -1)  # Yellow dot\n",
    "        \n",
    "        # Draw goal position\n",
    "        goal_pos_left = world_to_img_left(goal_pos[0], goal_pos[1])\n",
    "        goal_pos_right = world_to_img_right(goal_pos[0], goal_pos[1])\n",
    "        cv2.circle(combined_img, goal_pos_left, 5, (0, 255, 0), -1)  # Green dot\n",
    "        cv2.circle(combined_img, goal_pos_right, 5, (0, 255, 0), -1)  # Green dot\n",
    "        \n",
    "        # Add text overlay\n",
    "        info_text = [\n",
    "            f\"Position: ({current_pos[0]:.2f}, {current_pos[1]:.2f})\",\n",
    "            f\"Angle: {np.degrees(angle):.1f}°\",\n",
    "            f\"LiDAR points: {len(lidar_points)}\",\n",
    "            \"Press 'Q' to quit\"\n",
    "        ]\n",
    "        \n",
    "        for i, text in enumerate(info_text):\n",
    "            cv2.putText(combined_img, text, (10, 30 + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Show the combined image\n",
    "        cv2.imshow('LiDAR Test', combined_img)\n",
    "        \n",
    "        # Handle keyboard input\n",
    "        key = cv2.waitKey(30) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            running = False\n",
    "    \n",
    "    # Cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
